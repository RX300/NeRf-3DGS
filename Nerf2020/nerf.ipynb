{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://zhuanlan.zhihu.com/p/482154458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "#“npz”数据包含相机的焦距、相机拍摄的图像和相机拍摄时的姿势\n",
    "if not os.path.exists('tiny_nerf_data.npz'):\n",
    "    !wget http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/ECCV20/nerf/tiny_nerf_data.npz\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "torch.manual_seed(999) #通过指定seed值，可以保证每次执行 torch.manual_seed()后生成的随机数都相同\n",
    "np.random.seed(666)\n",
    "torch.backends.cudnn.benchmark=True #提升卷积神经网络的运行速度\n",
    "#加载数据，位姿，焦距\n",
    "data = np.load('tiny_nerf_data.npz')\n",
    "images = data['images']\n",
    "poses = data['poses']\n",
    "focal = data['focal']\n",
    "H, W = images.shape[1:3]\n",
    "print(\"images.shape:\", images.shape)\n",
    "print(\"poses.shape:\", poses.shape)\n",
    "print(\"focal:\", focal)\n",
    "\n",
    "n_train = 100 # use n_train images for training\n",
    "\n",
    "test_img, test_pose = images[101], poses[101]\n",
    "images = images[:n_train]\n",
    "poses = poses[:n_train]\n",
    "\n",
    "plt.imshow(test_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class NeRF(nn.Module):\n",
    "    #\n",
    "    def __init__(self, D=8, W=256, input_ch=60, input_ch_views=24, skip=4, use_view_dirs=True):\n",
    "        super(NeRF, self).__init__()\n",
    "        self.D = D\n",
    "        self.W = W\n",
    "        self.input_ch = input_ch\n",
    "        self.input_ch_views = input_ch_views\n",
    "        self.skip = skip\n",
    "        self.use_view_dirs = use_view_dirs\n",
    "\n",
    "        self.net = nn.ModuleList([nn.Linear(input_ch, W)])\n",
    "        for i in range(D-1):\n",
    "            if i == skip:\n",
    "                self.net.append(nn.Linear(W + input_ch, W))\n",
    "            else:\n",
    "                self.net.append(nn.Linear(W, W))\n",
    "\n",
    "        self.alpha_linear = nn.Linear(W, 1)\n",
    "        self.feature_linear = nn.Linear(W, W)\n",
    "        if use_view_dirs:\n",
    "            self.proj = nn.Linear(W + input_ch_views, W // 2)\n",
    "        else:\n",
    "            self.proj = nn.Linear(W, W // 2)\n",
    "        self.rgb_linear = nn.Linear(W // 2, 3)\n",
    "\n",
    "    def forward(self, input_pts, input_views=None):\n",
    "        h = input_pts.clone()\n",
    "        for i, _ in enumerate(self.net):\n",
    "            h = F.relu(self.net[i](h))\n",
    "            if i == self.skip:\n",
    "                h = torch.cat([input_pts, h], -1)\n",
    "\n",
    "        alpha = F.relu(self.alpha_linear(h))\n",
    "        feature = self.feature_linear(h)\n",
    "\n",
    "        if self.use_view_dirs:\n",
    "            h = torch.cat([feature, input_views], -1)\n",
    "\n",
    "        h = F.relu(self.proj(h))\n",
    "        rgb = torch.sigmoid(self.rgb_linear(h))\n",
    "\n",
    "        return rgb, alpha\n",
    "\n",
    "net = NeRF(use_view_dirs=True)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def PE(x, L):#位置编码 低频信息转换为高频信息-  x代表输入给编码器的数据维度，也就是3，2,5， l为数学公式中的L\n",
    "    #这个函数对x坐标的3个值和向量d 的2个值都进行了编码。实验中设置了 L=10 for y(x)，L=4 for y（d）\n",
    "#这里为了方便统一处理，应该会影响最后效果\n",
    "  pai = 3.14\n",
    "  pe = []\n",
    "  for i in range(L):\n",
    "    for fn in [torch.sin, torch.cos]:#依次 先后读取sin cos 函数\n",
    "      pe.append(fn(2.**i * x * pai))\n",
    "  return torch.cat(pe, -1)  #对tensor 进行拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sample_rays_np(H, W, f, c2w):#\n",
    "    i, j = np.meshgrid(np.arange(W, dtype=np.float32), np.arange(H, dtype=np.float32), indexing='xy')\n",
    "    dirs = np.stack([(i-W*.5+.5)/f, -(j-H*.5+.5)/f, -np.ones_like(i)], -1)\n",
    "    rays_d = np.sum(dirs[..., None, :] * c2w[:3,:3], -1)\n",
    "    rays_o = np.broadcast_to(c2w[:3,-1], np.shape(rays_d))\n",
    "    return rays_o, rays_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def uniform_sample_point(tn, tf, N_samples, device): # 归一化 采样的点，可以理解为把光线的原点移到near平面\n",
    "    k = torch.rand([N_samples], device=device) / float(N_samples)\n",
    "    pt_value = torch.linspace(0.0, 1.0, N_samples + 1, device=device)[:-1]\n",
    "    pt_value += k\n",
    "    return tn + (tf - tn) * pt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Hierarchical sampling (section 5.2)\n",
    "#大概步骤 1根据pdf 求 cdf 2 做0-1的均匀采样 3求采样点值在cdf中的对应分块和传播时间 4求解采样点对应的z_vals\n",
    "def sample_pdf_point(bins, weights, N_samples, device):\n",
    "    pdf = F.normalize(weights, p=1, dim=-1)\n",
    "    cdf = torch.cumsum(pdf, -1)\n",
    "    cdf = torch.cat([torch.zeros_like(cdf[..., :1]), cdf], -1)\n",
    "\n",
    "    # uniform sampling\n",
    "    u = torch.rand(list(cdf.shape[:-1]) + [N_samples], device=device).contiguous()\n",
    "\n",
    "    # invert\n",
    "    ids = torch.searchsorted(cdf, u, right=True)\n",
    "    below = torch.max(torch.zeros_like(ids - 1, device=device), ids - 1)\n",
    "    above = torch.min((cdf.shape[-1] - 1) * torch.ones_like(ids, device=device), ids)\n",
    "    ids_g = torch.stack([below, above], -1)\n",
    "    # ids_g => (batch, N_samples, 2)\n",
    "\n",
    "    # matched_shape : [batch, N_samples, bins]\n",
    "    matched_shape = [ids_g.shape[0], ids_g.shape[1], cdf.shape[-1]]\n",
    "    # gather cdf value\n",
    "    cdf_val = torch.gather(cdf.unsqueeze(1).expand(matched_shape), -1, ids_g)\n",
    "    # gather z_val\n",
    "    bins_val = torch.gather(bins[None, None, :].expand(matched_shape), -1, ids_g)\n",
    "\n",
    "    # get z_val for the fine sampling\n",
    "    cdf_d = (cdf_val[..., 1] - cdf_val[..., 0])\n",
    "    cdf_d = torch.where(cdf_d < 1e-5, torch.ones_like(cdf_d, device=device), cdf_d)\n",
    "    t = (u - cdf_val[..., 0]) / cdf_d\n",
    "    samples = bins_val[..., 0] + t * (bins_val[..., 1] - bins_val[..., 0])\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_rgb_w(net, pts, rays_d, z_vals, device, noise_std=.0, use_view=False):\n",
    "    # pts => tensor(Batch_Size, uniform_N, 3)\n",
    "    # rays_d => tensor(Batch_Size, 3)\n",
    "    # Run network\n",
    "    pts_flat = torch.reshape(pts, [-1, 3])\n",
    "    pts_flat = PE(pts_flat, L=10)\n",
    "    dir_flat = None\n",
    "    if use_view:\n",
    "        dir_flat = F.normalize(torch.reshape(rays_d.unsqueeze(-2).expand_as(pts), [-1, 3]), p=2, dim=-1)\n",
    "        dir_flat = PE(dir_flat, L=4)\n",
    "\n",
    "    rgb, sigma = net(pts_flat, dir_flat)\n",
    "    rgb = rgb.view(list(pts.shape[:-1]) + [3])\n",
    "    sigma = sigma.view(list(pts.shape[:-1]))\n",
    "\n",
    "    # get the interval\n",
    "    delta = z_vals[..., 1:] - z_vals[..., :-1]\n",
    "    INF = torch.ones(delta[..., :1].shape, device=device).fill_(1e10)\n",
    "    delta = torch.cat([delta, INF], -1)\n",
    "    delta = delta * torch.norm(rays_d, dim=-1, keepdim=True)\n",
    "\n",
    "    # add noise to sigma\n",
    "    if noise_std > 0.:\n",
    "        sigma += torch.randn(sigma.size(), device=device) * noise_std\n",
    "\n",
    "    # get weights\n",
    "    alpha = 1. - torch.exp(-sigma * delta)\n",
    "    ones = torch.ones(alpha[..., :1].shape, device=device)\n",
    "    weights = alpha * torch.cumprod(torch.cat([ones, 1. - alpha], dim=-1), dim=-1)[..., :-1]\n",
    "\n",
    "    return rgb, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def render_rays(net, rays, bound, N_samples, device, noise_std=.0, use_view=False):\n",
    "    rays_o, rays_d = rays\n",
    "    bs = rays_o.shape[0]\n",
    "    near, far = bound\n",
    "    uniform_N, important_N = N_samples\n",
    "    z_vals = uniform_sample_point(near, far, uniform_N, device)\n",
    "    pts = rays_o[..., None, :] + rays_d[..., None, :] * z_vals[..., None]\n",
    "    # pts => tensor(Batch_Size, uniform_N, 3)\n",
    "    # rays_o, rays_d => tensor(Batch_Size, 3)\n",
    "\n",
    "    # Run network\n",
    "    if important_N is not None:\n",
    "        with torch.no_grad():\n",
    "            rgb, weights = get_rgb_w(net, pts, rays_d, z_vals, device, noise_std=noise_std, use_view=use_view)\n",
    "            z_vals_mid = .5 * (z_vals[..., 1:] + z_vals[..., :-1])\n",
    "            samples = sample_pdf_point(z_vals_mid, weights[..., 1:-1], important_N, device)\n",
    "\n",
    "        z_vals = z_vals.unsqueeze(0).expand([bs, uniform_N])\n",
    "        z_vals, _ = torch.sort(torch.cat([z_vals, samples], dim=-1), dim=-1)\n",
    "        pts = rays_o[..., None, :] + rays_d[..., None, :] * z_vals[..., None]\n",
    "\n",
    "    rgb, weights = get_rgb_w(net, pts, rays_d, z_vals, device, noise_std=noise_std, use_view=use_view)\n",
    "\n",
    "    rgb_map = torch.sum(weights[..., None] * rgb, dim=-2)\n",
    "    depth_map = torch.sum(weights * z_vals, -1)\n",
    "    acc_map = torch.sum(weights, -1)\n",
    "\n",
    "    return rgb_map, depth_map, acc_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Process rays data!\")\n",
    "rays_o_list = list()\n",
    "rays_d_list = list()\n",
    "rays_rgb_list = list()\n",
    "\n",
    "for i in range(n_train):\n",
    "    img = images[i]\n",
    "    pose = poses[i]\n",
    "    rays_o, rays_d = sample_rays_np(H, W, focal, pose)\n",
    "\n",
    "    rays_o_list.append(rays_o.reshape(-1, 3))\n",
    "    rays_d_list.append(rays_d.reshape(-1, 3))\n",
    "    rays_rgb_list.append(img.reshape(-1, 3))\n",
    "\n",
    "rays_o_npy = np.concatenate(rays_o_list, axis=0)\n",
    "rays_d_npy = np.concatenate(rays_d_list, axis=0)\n",
    "rays_rgb_npy = np.concatenate(rays_rgb_list, axis=0)\n",
    "rays = torch.tensor(np.concatenate([rays_o_npy, rays_d_npy, rays_rgb_npy], axis=1), device=device)\n",
    "# rays => tensor(N_rays, 9) => o+d+rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "# training parameters\n",
    "#############################   Batch_size = 4096\n",
    "N = rays.shape[0]\n",
    "Batch_size = 1024\n",
    "iterations = N // Batch_size\n",
    "print(f\"There are {iterations} batches of rays and each batch contains {Batch_size} rays\")\n",
    "\n",
    "bound = (2., 6.)\n",
    "N_samples = (64, None)\n",
    "use_view = True\n",
    "epoch = 200\n",
    "psnr_list = []\n",
    "e_nums = []\n",
    "\n",
    "#############################\n",
    "# test data\n",
    "#############################\n",
    "test_rays_o, test_rays_d = sample_rays_np(H, W, focal, test_pose)\n",
    "test_rays_o = torch.tensor(test_rays_o, device=device)\n",
    "test_rays_d = torch.tensor(test_rays_d, device=device)\n",
    "test_rgb = torch.tensor(test_img, device=device)\n",
    "\n",
    "\n",
    "#############################\n",
    "# training\n",
    "#############################\n",
    "net = NeRF(use_view_dirs=use_view).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), 5e-4)\n",
    "mse = torch.nn.MSELoss()\n",
    "\n",
    "for e in range(epoch):\n",
    "    # create iteration for training\n",
    "    rays = rays[torch.randperm(N), :]\n",
    "    train_iter = iter(torch.split(rays, Batch_size, dim=0))\n",
    "\n",
    "    # render + mse\n",
    "    with tqdm(total=iterations, desc=f\"Epoch {e+1}\", ncols=100) as p_bar:\n",
    "        for i in range(iterations):\n",
    "            train_rays = next(train_iter)\n",
    "            assert train_rays.shape == (Batch_size, 9)\n",
    "\n",
    "            rays_o, rays_d, target_rgb = torch.chunk(train_rays, 3, dim=-1)\n",
    "            rays_od = (rays_o, rays_d)\n",
    "            rgb, _, __ = render_rays(net, rays_od, bound=bound, N_samples=N_samples, device=device, use_view=use_view)\n",
    "\n",
    "            loss = mse(rgb, target_rgb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            p_bar.set_postfix({'loss': '{0:1.5f}'.format(loss.item())})\n",
    "            p_bar.update(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        rgb_list = list()\n",
    "        for j in range(test_rays_o.shape[0]):\n",
    "            rays_od = (test_rays_o[j], test_rays_d[j])\n",
    "            rgb, _, __ = render_rays(net, rays_od, bound=bound, N_samples=N_samples, device=device, use_view=use_view)\n",
    "            rgb_list.append(rgb.unsqueeze(0))\n",
    "        rgb = torch.cat(rgb_list, dim=0)\n",
    "        loss = mse(rgb, torch.tensor(test_img, device=device)).cpu()\n",
    "        psnr = -10. * torch.log(loss).item() / torch.log(torch.tensor([10.]))\n",
    "        print(f\"PSNR={psnr.item()}\")\n",
    "        if(e % 50 == 0):\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.subplot(121)\n",
    "            plt.imshow(rgb.cpu().detach().numpy())\n",
    "            plt.title(f'Epoch: {e + 1}')\n",
    "            plt.subplot(122)\n",
    "\n",
    "            e_nums.append(e+1)\n",
    "            psnr_list.append(psnr.numpy())\n",
    "            plt.plot(e_nums, psnr_list)\n",
    "            plt.title('PSNR')\n",
    "            plt.show()\n",
    "            #保存在output文件夹下\n",
    "            if not os.path.exists('output'):\n",
    "                os.makedirs('output')\n",
    "            plt.imsave(f'output/{e}.png', rgb.cpu().detach().numpy())\n",
    "\n",
    "print('Done')\n",
    "net = NeRF(use_view_dirs=True)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interactive, widgets\n",
    "\n",
    "\n",
    "trans_t = lambda t : np.array([\n",
    "    [1,0,0,0],\n",
    "    [0,1,0,0],\n",
    "    [0,0,1,t],\n",
    "    [0,0,0,1],\n",
    "], dtype=float)\n",
    "\n",
    "rot_phi = lambda phi : np.array([\n",
    "    [1,0,0,0],\n",
    "    [0,np.cos(phi),-np.sin(phi),0],\n",
    "    [0,np.sin(phi), np.cos(phi),0],\n",
    "    [0,0,0,1],\n",
    "], dtype=float)\n",
    "\n",
    "rot_theta = lambda th : np.array([\n",
    "    [np.cos(th),0,-np.sin(th),0],\n",
    "    [0,1,0,0],\n",
    "    [np.sin(th),0, np.cos(th),0],\n",
    "    [0,0,0,1],\n",
    "], dtype=float)\n",
    "\n",
    "\n",
    "def pose_spherical(theta, phi, radius):\n",
    "    c2w = trans_t(radius)\n",
    "    c2w = rot_phi(phi/180.*np.pi) @ c2w\n",
    "    c2w = rot_theta(theta/180.*np.pi) @ c2w\n",
    "    c2w = np.array([[-1,0,0,0],[0,0,1,0],[0,1,0,0],[0,0,0,1]]) @ c2w\n",
    "    return c2w\n",
    "\n",
    "\n",
    "def f(**kwargs):\n",
    "    c2w = pose_spherical(**kwargs)\n",
    "    rays_o, rays_d = sample_rays_np(H, W, focal, c2w[:3,:4])\n",
    "    with torch.no_grad():\n",
    "      rays_o = torch.tensor(rays_o, device=device)\n",
    "      rays_d = torch.tensor(rays_d, device=device)\n",
    "      rgb_list = list()\n",
    "      for j in range(rays_o.shape[0]):\n",
    "        rays_od = (rays_o[j], rays_d[j])\n",
    "        rgb, _, __ = render_rays(net, rays_od, bound=bound, N_samples=N_samples, device=device, use_view=use_view)\n",
    "        rgb_list.append(rgb.unsqueeze(0))\n",
    "      rgb = torch.cat(rgb_list, dim=0)\n",
    "\n",
    "    plt.figure(2, figsize=(20,6))\n",
    "    plt.imshow(rgb.cpu().detach().numpy())\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "sldr = lambda v, mi, ma: widgets.FloatSlider(\n",
    "    value=v,\n",
    "    min=mi,\n",
    "    max=ma,\n",
    "    step=.01,\n",
    ")\n",
    "\n",
    "names = [\n",
    "    ['theta', [100., 0., 360]],\n",
    "    ['phi', [-30., -90, 0]],\n",
    "    ['radius', [4., 3., 5.]],\n",
    "]\n",
    "\n",
    "# interactive_plot = interactive(f, **{s[0] : sldr(*s[1]) for s in names})\n",
    "# output = interactive_plot.children[-1]\n",
    "# output.layout.height = '350px'\n",
    "# interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "for th in tqdm(np.linspace(0., 360., 120, endpoint=False)):\n",
    "    with torch.no_grad():\n",
    "      c2w = pose_spherical(th, -30., 4.)\n",
    "      rays_o, rays_d = sample_rays_np(H, W, focal, c2w[:3,:4])\n",
    "      rays_od = (torch.tensor(rays_o, device=device,dtype=torch.float32),torch.tensor(rays_d, device=device,dtype=torch.float32))\n",
    "      rgb, depth, acc = render_rays(net, rays_od, bound=bound, N_samples=N_samples, device=device, use_view=use_view)\n",
    "    frames.append((255*np.clip(rgb.cpu().numpy(),0,1)).astype(np.uint8))\n",
    "\n",
    "import imageio\n",
    "f = 'video.mp4'\n",
    "imageio.mimwrite(f, frames, fps=30, quality=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "mp4 = open('video.mp4','rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"\n",
    "<video width=400 controls autoplay loop>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AiStudy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
